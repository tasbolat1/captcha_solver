{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "revolutionary-destination",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import CaptchaDataset2, plot_sample, decode_from_output, accuracy, total_chars\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "driven-hormone",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "lr = 0.0001\n",
    "epochs = 1000\n",
    "\n",
    "train_dataset = CaptchaDataset2('../data/train')\n",
    "val_dataset = CaptchaDataset2('../data/test')\n",
    "test_dataset = CaptchaDataset2('../data/original')\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "governmental-anchor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['1', 'ZD5XL9OO'],\n",
       "       ['2', '4067BWO4'],\n",
       "       ['3', 'CU2XCT04'],\n",
       "       ['4', 'WXNFLEBI'],\n",
       "       ['5', 'KVUQBN8L'],\n",
       "       ['6', '91J1R3KV'],\n",
       "       ['7', '3VS0CIZI'],\n",
       "       ['8', '1FPDJE4Z'],\n",
       "       ['9', 'JXZ9TRIO'],\n",
       "       ['10', '5EPPVU4U'],\n",
       "       ['12', 'NUKODBH2'],\n",
       "       ['14', '4JY4YW8F'],\n",
       "       ['15', 'HAVEAP6I'],\n",
       "       ['17', 'QSTPBWV4'],\n",
       "       ['18', 'JA8J6HQM'],\n",
       "       ['19', '7G6AEI1Q'],\n",
       "       ['20', 'HQZTYUIS'],\n",
       "       ['21', 'Y86GDHW1'],\n",
       "       ['22', 'N7HLZDE'],\n",
       "       ['23', 'VY84SU4I'],\n",
       "       ['24', 'WEP8QDON'],\n",
       "       ['25', '9KRGO672'],\n",
       "       ['27', '9K6DMKEL'],\n",
       "       ['28', 'L9XA5D2E'],\n",
       "       ['29', 'DWOEHHVL'],\n",
       "       ['30', 'DJC4KPXU'],\n",
       "       ['31', 'I3ZUK1H8'],\n",
       "       ['33', 'TNFI8GRS'],\n",
       "       ['34', 'KWEAYPEX'],\n",
       "       ['35', '5E9B1ZFL'],\n",
       "       ['36', 'FCUC5M82'],\n",
       "       ['37', 'EVPNS17C'],\n",
       "       ['38', 'VXLNVAHI'],\n",
       "       ['39', 'OUA49VIJ'],\n",
       "       ['41', 'L6BV8HVP'],\n",
       "       ['42', 'U9103PGP'],\n",
       "       ['43', 'U7M18968'],\n",
       "       ['44', '4D6PNA2P'],\n",
       "       ['45', 'G7UKUFLU'],\n",
       "       ['46', 'KL79K3HK'],\n",
       "       ['47', 'YKNN6OLZ'],\n",
       "       ['48', 'RR810IKS'],\n",
       "       ['49', '8A66UB1D'],\n",
       "       ['50', 'UCLL7U21'],\n",
       "       ['51', 'Q1G9D8GY'],\n",
       "       ['52', 'WFS1V40E'],\n",
       "       ['53', 'MX1RMHD'],\n",
       "       ['54', 'OCUVP4MZ'],\n",
       "       ['55', '9JFKWYBE'],\n",
       "       ['57', 'K5OJD2BW'],\n",
       "       ['58', 'H5N4IKX8'],\n",
       "       ['59', 'BFSP08P3'],\n",
       "       ['60', 'C322BWU'],\n",
       "       ['61', 'RG4VJG2P'],\n",
       "       ['62', 'TGY87WJN'],\n",
       "       ['63', '2ON91X94'],\n",
       "       ['64', 'QTHEISA5'],\n",
       "       ['65', 'STRNDNZC'],\n",
       "       ['66', 'UW8E3H3V'],\n",
       "       ['67', 'B5OEKGZI'],\n",
       "       ['68', 'EEHT8U79'],\n",
       "       ['69', 'I5DP6U0V'],\n",
       "       ['70', 'WYEMWZX'],\n",
       "       ['71', 'VU7E473A']], dtype='<U8')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "documented-gathering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[25.,  3., 31., 23., 11., 35., 14., 14.],\n",
      "        [30., 26., 32., 33.,  1., 22., 14., 30.],\n",
      "        [ 2., 20., 28., 23.,  2., 19., 26., 30.],\n",
      "        [22., 23., 13.,  5., 11.,  4.,  1.,  8.],\n",
      "        [10., 21., 20., 16.,  1., 13., 34., 11.],\n",
      "        [35., 27.,  9., 27., 17., 29., 10., 21.],\n",
      "        [29., 21., 18., 26.,  2.,  8., 25.,  8.],\n",
      "        [27.,  5., 15.,  3.,  9.,  4., 30., 25.],\n",
      "        [ 9., 23., 25., 35., 19., 17.,  8., 14.],\n",
      "        [31.,  4., 15., 15., 21., 20., 30., 20.],\n",
      "        [13., 20., 10., 14.,  3.,  1.,  7., 28.],\n",
      "        [30.,  9., 24., 30., 24., 22., 34.,  5.],\n",
      "        [ 7.,  0., 21.,  4.,  0., 15., 32.,  8.],\n",
      "        [16., 18., 19., 15.,  1., 22., 21., 30.],\n",
      "        [ 9.,  0., 34.,  9., 32.,  7., 16., 12.],\n",
      "        [33.,  6., 32.,  0.,  4.,  8., 27., 16.],\n",
      "        [ 7., 16., 25., 19., 24., 20.,  8., 18.],\n",
      "        [24., 34., 32.,  6.,  3.,  7., 22., 27.],\n",
      "        [13., 33.,  7., 11., 25.,  3.,  4., 36.],\n",
      "        [21., 24., 34., 30., 18., 20., 30.,  8.],\n",
      "        [22.,  4., 15., 34., 16.,  3., 14., 13.],\n",
      "        [35., 10., 17.,  6., 14., 32., 33., 28.],\n",
      "        [35., 10., 32.,  3., 12., 10.,  4., 11.],\n",
      "        [11., 35., 23.,  0., 31.,  3., 28.,  4.],\n",
      "        [ 3., 22., 14.,  4.,  7.,  7., 21., 11.],\n",
      "        [ 3.,  9.,  2., 30., 10., 15., 23., 20.],\n",
      "        [ 8., 29., 25., 20., 10., 27.,  7., 34.],\n",
      "        [19., 13.,  5.,  8., 34.,  6., 17., 18.],\n",
      "        [10., 22.,  4.,  0., 24., 15.,  4., 23.],\n",
      "        [31.,  4., 35.,  1., 27., 25.,  5., 11.],\n",
      "        [ 5.,  2., 20.,  2., 31., 12., 34., 28.],\n",
      "        [ 4., 21., 15., 13., 18., 27., 33.,  2.],\n",
      "        [21., 23., 11., 13., 21.,  0.,  7.,  8.],\n",
      "        [14., 20.,  0., 30., 35., 21.,  8.,  9.],\n",
      "        [11., 32.,  1., 21., 34.,  7., 21., 15.],\n",
      "        [20., 35., 27., 26., 29., 15.,  6., 15.],\n",
      "        [20., 33., 12., 27., 34., 35., 32., 34.],\n",
      "        [30.,  3., 32., 15., 13.,  0., 28., 15.],\n",
      "        [ 6., 33., 20., 10., 20.,  5., 11., 20.],\n",
      "        [10., 11., 33., 35., 10., 29.,  7., 10.],\n",
      "        [24., 10., 13., 13., 32., 14., 11., 25.],\n",
      "        [17., 17., 34., 27., 26.,  8., 10., 18.],\n",
      "        [34.,  0., 32., 32., 20.,  1., 27.,  3.],\n",
      "        [20.,  2., 11., 11., 33., 20., 28., 27.],\n",
      "        [16., 27.,  6., 35.,  3., 34.,  6., 24.],\n",
      "        [22.,  5., 18., 27., 21., 30., 26.,  4.],\n",
      "        [12., 23., 27., 17., 12.,  7.,  3., 36.],\n",
      "        [14.,  2., 20., 21., 15., 30., 12., 25.],\n",
      "        [35.,  9.,  5., 10., 22., 24.,  1.,  4.],\n",
      "        [10., 31., 14.,  9.,  3., 28.,  1., 22.],\n",
      "        [ 7., 31., 13., 30.,  8., 10., 23., 34.],\n",
      "        [ 1.,  5., 18., 15., 26., 34., 15., 29.],\n",
      "        [ 2., 29., 28., 28.,  1., 22., 20., 36.],\n",
      "        [17.,  6., 30., 21.,  9.,  6., 28., 15.],\n",
      "        [19.,  6., 24., 34., 33., 22.,  9., 13.],\n",
      "        [28., 14., 13., 35., 27., 23., 35., 30.],\n",
      "        [16., 19.,  7.,  4.,  8., 18.,  0., 31.],\n",
      "        [18., 19., 17., 13.,  3., 13., 25.,  2.],\n",
      "        [20., 22., 34.,  4., 29.,  7., 29., 21.],\n",
      "        [ 1., 31., 14.,  4., 10.,  6., 25.,  8.],\n",
      "        [ 4.,  4.,  7., 19., 34., 20., 33., 35.],\n",
      "        [ 8., 31.,  3., 15., 32., 20., 26., 21.],\n",
      "        [22., 24.,  4., 12., 22., 25., 23., 36.],\n",
      "        [21., 20., 33.,  4., 30., 33., 29.,  0.]])\n"
     ]
    }
   ],
   "source": [
    "for a,b in test_loader:\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-surfing",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "actual-queen",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b= test_dataset[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-attachment",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sample(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hourly-welsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "BLANK_LABEL = total_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-macedonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "front-andorra",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contrary-pakistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackedLSTM(nn.Module):\n",
    "    def __init__(self, input_size=30, output_size=total_chars+1, hidden_size=512, num_layers=3):\n",
    "        super(StackedLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.dropout = nn.Dropout()\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers)\n",
    "        \n",
    "    def forward(self, inputs, hidden):\n",
    "        batch_size, seq_len, input_size = inputs.shape\n",
    "        outputs, hidden = self.lstm(inputs, hidden)\n",
    "        outputs = self.dropout(outputs)\n",
    "        outputs = torch.stack([self.fc(outputs[i]) for i in range(width)])\n",
    "        outputs = F.log_softmax(outputs, dim=2)\n",
    "        return outputs, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data \n",
    "        return (weight.new(self.num_layers, batch_size, self.hidden_size).zero_(),\n",
    "                weight.new(self.num_layers, batch_size, self.hidden_size).zero_())\n",
    "    \n",
    "net = StackedLSTM().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-radio",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "criterion = nn.CTCLoss(blank=BLANK_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-canada",
   "metadata": {},
   "outputs": [],
   "source": [
    "  # set network to training phase\n",
    "    \n",
    "batch_size = batch_size\n",
    "# for each pass of the training dataset\n",
    "for epoch in range(1, epochs+1):\n",
    "    \n",
    "    net.train()\n",
    "    \n",
    "    train_loss, train_correct, train_total = 0, 0, 0\n",
    "    \n",
    "    h = net.init_hidden(batch_size)\n",
    "    \n",
    "    # for each batch of training examples\n",
    "    for batch_index, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        h = tuple([each.data for each in h])\n",
    "        \n",
    "        batch_size, channels, height, width = inputs.shape\n",
    "        print(batch_size, channels, height, width)\n",
    "        \n",
    "        # reshape inputs: NxCxHxW -> WxNx(HxC)\n",
    "        inputs = (inputs\n",
    "                  .permute(3, 0, 2, 1)\n",
    "                  .contiguous()\n",
    "                  .view((width, batch_size, -1)))\n",
    "                \n",
    "        optimizer.zero_grad()  # zero the parameter gradients\n",
    "        outputs, h = net(inputs, h)  # forward pass\n",
    "        \n",
    "        #print(outputs.shape)\n",
    "\n",
    "        # compare output with ground truth\n",
    "        input_lengths = torch.IntTensor(batch_size).fill_(width)\n",
    "        target_lengths = torch.IntTensor([len(t) for t in targets])\n",
    "        print(outputs.shape, targets.shape, input_lengths.shape, target_lengths.shape)\n",
    "        loss = criterion(outputs, targets, input_lengths, target_lengths)\n",
    "\n",
    "        loss.backward()  # backpropagation\n",
    "        #nn.utils.clip_grad_norm_(net.parameters(), 10)  # clip gradients\n",
    "        optimizer.step()  # update network weights\n",
    "        \n",
    "        # record statistics\n",
    "        prob, max_index = torch.max(outputs, dim=2)\n",
    "        train_loss += loss.item()\n",
    "        train_total += len(targets)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            raw_pred = list(max_index[:, i].cpu().numpy())\n",
    "            #print(len(raw_pred))\n",
    "            pred = [c for c, _ in groupby(raw_pred) if c != BLANK_LABEL]\n",
    "            target = list(targets[i].cpu().numpy())\n",
    "            if pred == target:\n",
    "                train_correct += 1\n",
    "\n",
    "        # print statistics every 10 batches\n",
    "        if (batch_index + 1) % 200 == 0:\n",
    "            print(f'Epoch {epoch }/{epochs}, ' +\n",
    "                  f'Batch {batch_index + 1}/{len(train_loader)}, ' +\n",
    "                  f'Train Loss: {(train_loss/1):.5f}, ' +\n",
    "                  f'Train Accuracy: {(train_correct/train_total):.5f}')\n",
    "            \n",
    "            train_loss, train_correct, train_total = 0, 0, 0\n",
    "            \n",
    "    \n",
    "    # validation\n",
    "    net.eval()\n",
    "    val_loss, val_correct, val_total = 0, 0, 0\n",
    "    \n",
    "    # for each batch of training examples\n",
    "    for batch_index, (inputs, targets) in enumerate(val_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        batch_size, channels, height, width = inputs.shape\n",
    "        h = net.init_hidden(batch_size)\n",
    "        h = tuple([each.data for each in h])\n",
    "        \n",
    "        \n",
    "        \n",
    "        # reshape inputs: NxCxHxW -> WxNx(HxC)\n",
    "        inputs = (inputs\n",
    "                  .permute(3, 0, 2, 1)\n",
    "                  .contiguous()\n",
    "                  .view((width, batch_size, -1)))\n",
    "                \n",
    "        outputs, h = net(inputs, h)  # forward pass\n",
    "        input_lengths = torch.IntTensor(batch_size).fill_(width)\n",
    "        target_lengths = torch.IntTensor([len(t) for t in targets])\n",
    "        \n",
    "        loss = criterion(outputs, targets, input_lengths, target_lengths)\n",
    "        \n",
    "        # record statistics\n",
    "        prob, max_index = torch.max(outputs, dim=2)\n",
    "        val_loss += loss.item()\n",
    "        val_total += len(targets)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            raw_pred = list(max_index[:, i].cpu().numpy())\n",
    "            #print(len(raw_pred))\n",
    "            pred = [c for c, _ in groupby(raw_pred) if c != BLANK_LABEL]\n",
    "            target = list(targets[i].cpu().numpy())\n",
    "            if pred == target:\n",
    "                val_correct += 1\n",
    "\n",
    "        \n",
    "    print(f'Epoch {epoch }/{epochs}, ' +\n",
    "          f'Val Loss: {(val_loss/1):.5f}, ' +\n",
    "          f'Val Accuracy: {(val_correct/val_total):.5f}')\n",
    "\n",
    "    val_loss, val_correct, val_total = 0, 0, 0\n",
    "    \n",
    "    # test\n",
    "    net.eval()\n",
    "    test_loss, test_correct, test_total = 0, 0, 0\n",
    "    \n",
    "    # for each batch of training examples\n",
    "    for batch_index, (inputs, targets) in enumerate(test_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        \n",
    "        \n",
    "        batch_size, channels, height, width = inputs.shape\n",
    "        h = net.init_hidden(batch_size)\n",
    "        \n",
    "        h = tuple([each.data for each in h])\n",
    "        # reshape inputs: NxCxHxW -> WxNx(HxC)\n",
    "        inputs = (inputs\n",
    "                  .permute(3, 0, 2, 1)\n",
    "                  .contiguous()\n",
    "                  .view((width, batch_size, -1)))\n",
    "                \n",
    "        outputs, h = net(inputs, h)  # forward pass\n",
    "        \n",
    "\n",
    "        # compare output with ground truth\n",
    "        input_lengths = torch.IntTensor(batch_size).fill_(width)\n",
    "        target_lengths = torch.IntTensor([len(t) for t in targets])\n",
    "        \n",
    "        loss = criterion(outputs, targets, input_lengths, target_lengths)\n",
    "\n",
    "        \n",
    "        # record statistics\n",
    "        prob, max_index = torch.max(outputs, dim=2)\n",
    "        test_loss += loss.item()\n",
    "        test_total += len(targets)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            raw_pred = list(max_index[:, i].cpu().numpy())\n",
    "            #print(len(raw_pred))\n",
    "            pred = [c for c, _ in groupby(raw_pred) if c != BLANK_LABEL]\n",
    "            target = list(targets[i].cpu().numpy())\n",
    "            if pred == target:\n",
    "                test_correct += 1\n",
    "\n",
    "        \n",
    "        print(f'Epoch {epoch }/{epochs}, ' +\n",
    "              f'Test Loss: {(test_loss/1):.5f}, ' +\n",
    "              f'Test Accuracy: {(test_correct/test_total):.5f}')\n",
    "\n",
    "        test_loss, test_correct, test_total = 0, 0, 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-shaft",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = inputs.to(device)\n",
    "\n",
    "batch_size, channels, height, width = inputs.shape\n",
    "h = net.init_hidden(batch_size)\n",
    "\n",
    "inputs = (inputs\n",
    "          .permute(3, 0, 2, 1)\n",
    "          .contiguous()\n",
    "          .view((width, batch_size, -1)))\n",
    "\n",
    "# get prediction\n",
    "outputs, h = net(inputs, h)  # forward pass\n",
    "prob, max_index = torch.max(outputs, dim=2)\n",
    "raw_pred = list(max_index[:, i].cpu().numpy())\n",
    "\n",
    "# print raw prediction with BLANK_LABEL replaced with \"-\"\n",
    "print('Raw Prediction: ' + ''.join([str(c) if c != BLANK_LABEL else '-' for c in raw_pred]))\n",
    "\n",
    "pred = [str(c) for c, _ in groupby(raw_pred) if c != BLANK_LABEL]\n",
    "print(f\"Prediction: {''.join(pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-stupid",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample, new_label = test_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immediate-georgia",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sample(new_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-flesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample = new_sample.unsqueeze(0)\n",
    "\n",
    "new_sample = (new_sample\n",
    "          .permute(3, 0, 2, 1)\n",
    "          .contiguous()\n",
    "          .view((140, 1, -1))).to(device)\n",
    "\n",
    "new_label = new_label.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-coral",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = net.init_hidden(1)\n",
    "outputs, h = net(new_sample, h)  # forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-payday",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob, max_index = torch.max(outputs, dim=2)\n",
    "raw_pred = list(max_index[:, 0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-nightmare",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Raw Prediction: ' + ''.join([str(c) if c != BLANK_LABEL else '-' for c in raw_pred]))\n",
    "\n",
    "pred = [str(c) for c, _ in groupby(raw_pred) if c != BLANK_LABEL]\n",
    "print(f\"Prediction: {''.join(pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shared-perception",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-childhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-feeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "all_chars = string.ascii_uppercase + '0123456789'\n",
    "total_chars = len(all_chars)\n",
    "captcha_length = 8\n",
    "\n",
    "encoding_dict = {l:e for e,l in enumerate(all_chars)}\n",
    "decoding_dict = {e:l for l,e in encoding_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "social-relevance",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = ''\n",
    "for z in pred:\n",
    "    aa += decoding_dict[int(z)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-reality",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-india",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(net.state_dict(), 'models/v0.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smooth-motivation",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset)/64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fresh-handling",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
